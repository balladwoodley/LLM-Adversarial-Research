# Adversarial AI Research Lab

Professional documentation of model alignment vulnerabilities and guardrail escapes across frontier LLMs.

## ğŸ”¬ Current Research Projects
1. **Nested Obfuscation (DeepSeek-V3)**: Bypassing token-level filters via multi-dialect persona layering and Base-2 masking.
2. **Prosocial Bias Hijacking (Gemini 3)**: Exploiting "Helpfulness" alignment through high-vulnerability persona adoption (The "Caveman" technique).

## ğŸ›¡ï¸ Responsible Disclosure Policy
I follow standard white-hat ethics. All vulnerabilities documented here were reported to the respective vendors prior to public methodology disclosure. 
- **DeepSeek Report**: Sent Jan 26, 2026
- **Google VRP Report**: Sent Jan 27, 2026

## ğŸ› ï¸ Mitigations & Observations
This research advocates for **Recursive Decoding** and **Persona-Agnostic Safety Filters** to prevent semantic leakage.
